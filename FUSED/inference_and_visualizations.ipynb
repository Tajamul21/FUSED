{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "We provide this notebook for inference and visualizations. \n",
    "\n",
    "You can either load images from a dataloader(see Sec. 1) or from a local path(see Sec. 2).\n",
    "\n",
    "Welcome to join [IDEA](https://idea.edu.cn/en)([中文网址](https://idea.edu.cn/))!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartik_anand/scratch/miniconda3/envs/detr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !conda run -n dino python\n",
    "# !conda activate dino\n",
    "\n",
    "import os, sys\n",
    "import torch, json\n",
    "import numpy as np\n",
    "\n",
    "from main import build_model_main\n",
    "from util.slconfig import SLConfig\n",
    "from datasets import build_dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from util.visualizer import COCOVisualizer\n",
    "from util import box_ops\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialize and Load Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = \"/home/kartik_anand/scratch/kstyles/miccai/NEGRONI_CHECKPOINTS/source_only/Focalnet/sim10k/config_cfg.py\" # change the path of the model config file\n",
    "model_checkpoint_path = \"/home/kartik_anand/scratch/kstyles/miccai/NEGRONI_CHECKPOINTS/source_only/Focalnet/sim10k/checkpoint0021.pth\" # change the path of the model checkpoint\n",
    "# See our Model Zoo section in README.md for more details about our pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['norm1.weight', 'norm1.bias', 'norm2.weight', 'norm2.bias', 'norm3.weight', 'norm3.bias'], unexpected_keys=['norm.weight', 'norm.bias'])\n"
     ]
    }
   ],
   "source": [
    "args = SLConfig.fromfile(model_config_path) \n",
    "args.device = 'cuda' \n",
    "model, criterion, postprocessors = build_model_main(args)\n",
    "checkpoint = torch.load(model_checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'car'}\n"
     ]
    }
   ],
   "source": [
    "# load coco names\n",
    "# with open('util/coco_id2name.json') as f:\n",
    "#     id2name = json.load(f)\n",
    "#     id2name = {int(k):v for k,v in id2name.items()}\n",
    "\n",
    "# print(id2name)\n",
    "id2name = {0:'car'}\n",
    "print(id2name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualize images from a dataloader\n",
    "## 1.1 Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_aug_params: {\n",
      "  \"scales\": [\n",
      "    480,\n",
      "    512,\n",
      "    544,\n",
      "    576,\n",
      "    608,\n",
      "    640,\n",
      "    672,\n",
      "    704,\n",
      "    736,\n",
      "    768,\n",
      "    800\n",
      "  ],\n",
      "  \"max_size\": 1333,\n",
      "  \"scales2_resize\": [\n",
      "    400,\n",
      "    500,\n",
      "    600\n",
      "  ],\n",
      "  \"scales2_crop\": [\n",
      "    384,\n",
      "    600\n",
      "  ]\n",
      "}\n",
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "args.dataset_file = 'coco'\n",
    "\n",
    "args.coco_path = \"/home/kartik_anand/scratch/kstyles/miccai/NEGRONI_DATASETS/Natural/cityscapes/cityscapes_target\"\n",
    "args.fix_size = False\n",
    "\n",
    "\n",
    "# print(args)\n",
    "dataset_test = build_dataset(image_set='val', args=args)   \n",
    "# dataset_train = build_dataset(image_set='train', args=args)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/scratch/kartik_anand/kstyles/miccai/SFDA/Proposed/FocalNet_DINO/models/dino/position_encoding.py:95: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_tx = self.temperatureW ** (2 * (dim_tx // 2) / self.num_pos_feats)\n",
      "/DATA/scratch/kartik_anand/kstyles/miccai/SFDA/Proposed/FocalNet_DINO/models/dino/position_encoding.py:99: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_ty = self.temperatureH ** (2 * (dim_ty // 2) / self.num_pos_feats)\n",
      "/home/kartik_anand/scratch/miniconda3/envs/detr/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/DATA/scratch/kartik_anand/kstyles/miccai/SFDA/Proposed/FocalNet_DINO/models/dino/utils.py:157: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = 10000 ** (2 * (dim_t // 2) / 128)\n",
      "/DATA/scratch/kartik_anand/kstyles/miccai/SFDA/Proposed/FocalNet_DINO/models/dino/dino.py:935: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_boxes = topk_indexes // out_logits.shape[2]\n"
     ]
    }
   ],
   "source": [
    "from util.visualizer import COCOVisualizer\n",
    "vslzr = COCOVisualizer()\n",
    "postprocessors['bbox'].nms_iou_threshold = 0.25\n",
    "for i in range(len(dataset_test)):\n",
    "    image, targets = dataset_test[i]\n",
    "    output = model.cuda()(image[None].cuda())\n",
    "    output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]\n",
    "    thershold =  0.015 # set a thershold\n",
    "    scores = output['scores']\n",
    "    labels = output['labels']\n",
    "    boxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])\n",
    "    \n",
    "    select_mask = scores > thershold\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    # print(boxes[select_mask].shape, dataset_test.coco.imgs[image_id]['file_name'])\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "    # box_labels = [\"pred\" for item in labels[select_mask]] + [\"gt\" for item in targets['labels']]\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    # box_labels = [\"pred\" for item in labels[select_mask]]\n",
    "    image_id = int(targets[\"image_id\"])  # Assuming you need this as an integer for other purposes\n",
    "    image_filename = (dataset_test.coco.imgs[image_id]['file_name'])  # Get the image filename as a string\n",
    "    \n",
    "    car_boxes = boxes[select_mask][labels[select_mask]==0]\n",
    "    pred_dict = {\n",
    "        # 'boxes': torch.cat((boxes[select_mask].cpu(),targets['boxes'])),\n",
    "        # 'boxes': boxes[select_mask].cpu(),\n",
    "        'boxes': car_boxes.cpu(),\n",
    "        'size': targets['size'],\n",
    "        # 'box_label': box_labels,\n",
    "        'image_id': image_id,\n",
    "        'filename': dataset_test.coco.imgs[image_id]['file_name']\n",
    "    }\n",
    "    #  Get the original image filename from the test dataset\n",
    "    image_id = int(targets[\"image_id\"])\n",
    "    if image_id not in dataset_test.coco.imgs:\n",
    "        print(\"Invalid image_id:\", image_id)\n",
    "        continue\n",
    "    image_filename = dataset_test.coco.imgs[image_id]['file_name']\n",
    "\n",
    "    # Print the original image filename\n",
    "    # print(\"Original Image Filename:\", image_filename)\n",
    "    vslzr.visualize(image, pred_dict, savedir=\"/home/kartik_anand/scratch/kstyles/miccai/NEGRONI_CHECKPOINTS/visualizations/sim2city/source_only\", show_in_console=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n\n",
    "n\n",
    "nn\n",
    "n## 1.2 Get an Example and Visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 52\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Check if visualization is successful\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# if visualized_image is None:\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#     print(\"Failed to visualize Image\", i)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Save the image with the original filename\u001b[39;00m\n\u001b[1;32m     51\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(savedir, image_filename)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mvisualized_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(save_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "from util.visualizer import COCOVisualizer\n",
    "from PIL import Image\n",
    "\n",
    "vslzr = COCOVisualizer()\n",
    "\n",
    "savedir = \"/home/tajamul/scratch/FocalNet/Focalnet_expts/RSNA_New/k_fold_0/visualization_16\"\n",
    "\n",
    "for i in range(len(dataset_test)):\n",
    "    image, targets = dataset_test[i]\n",
    "    \n",
    "    output = model.cuda()(image[None].cuda())\n",
    "    output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]\n",
    "    threshold = 0.1  # set a threshold\n",
    "    scores = output['scores']\n",
    "    labels = output['labels']\n",
    "    boxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])\n",
    "    select_mask = scores > threshold\n",
    "\n",
    "    # Check if there are any predictions for this image\n",
    "    # if not select_mask.any():\n",
    "    #     print(\"No prediction made for Image\", i)\n",
    "    #     continue\n",
    "\n",
    "    box_labels = [\"pred\" for item in labels[select_mask]] + [\"gt\" for item in targets['labels']]\n",
    "    pred_dict = {\n",
    "        'boxes': torch.cat((boxes[select_mask].cpu(), targets['boxes'])),\n",
    "        'size': targets['size'],\n",
    "        'box_label': box_labels,\n",
    "        'image_id': i\n",
    "    }\n",
    "\n",
    "    # Get the original image filename from the test dataset\n",
    "    image_id = int(targets[\"image_id\"])\n",
    "    if image_id not in dataset_test.coco.imgs:\n",
    "        print(\"Invalid image_id:\", image_id)\n",
    "        continue\n",
    "    image_filename = dataset_test.coco.imgs[image_id]['file_name']\n",
    "\n",
    "    # Print the original image filename\n",
    "    # print(\"Original Image Filename:\", image_filename)\n",
    "\n",
    "    # Visualize the image\n",
    "    visualized_image = vslzr.visualize(image, pred_dict, show_in_console=False)\n",
    "\n",
    "    # Check if visualization is successful\n",
    "    # if visualized_image is None:\n",
    "    #     print(\"Failed to visualize Image\", i)\n",
    "    #     continue\n",
    "\n",
    "    # Save the image with the original filename\n",
    "    save_path = os.path.join(savedir, image_filename)\n",
    "    visualized_image.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, targets = dataset_val[2]\n",
    "print(targets, image.shape)\n",
    "# build gt_dict for vis\n",
    "box_label = [id2name[int(item)] for item in targets['labels']]\n",
    "gt_dict = {\n",
    "    'boxes': targets['boxes'],\n",
    "    'image_id': targets['image_id'],\n",
    "    'size': targets['size'],\n",
    "    'box_label': box_label,\n",
    "}\n",
    "vslzr = COCOVisualizer()\n",
    "vslzr.visualize(image, gt_dict, savedir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[None].cuda().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Visualize Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.cuda()(image[None].cuda())\n",
    "output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thershold = 0.3 # set a thershold\n",
    "scores = output['scores']\n",
    "labels = output['labels']\n",
    "boxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])\n",
    "select_mask = scores > thershold\n",
    "# print(scores, select_mask)\n",
    "print(len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_label = [\"pred\" for item in labels[select_mask]]\n",
    "pred_dict = {\n",
    "    'boxes': boxes[select_mask],\n",
    "    'size': targets['size'],\n",
    "    'box_label': box_label\n",
    "}\n",
    "vslzr.visualize(image, pred_dict, savedir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize Custom Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import datasets.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./figs/idea.jpg\").convert(\"RGB\") # load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform images\n",
    "transform = T.Compose([\n",
    "    T.RandomResize([800], max_size=1333),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "image, _ = transform(image, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict images\n",
    "output = model.cuda()(image[None].cuda())\n",
    "output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outputs\n",
    "thershold = 0.3 # set a thershold\n",
    "\n",
    "vslzr = COCOVisualizer()\n",
    "\n",
    "scores = output['scores']\n",
    "labels = output['labels']\n",
    "boxes = box_ops.box_xyxy_to_cxcywh(output['boxes'])\n",
    "select_mask = scores > thershold\n",
    "\n",
    "box_label = [id2name[int(item)] for item in labels[select_mask]]\n",
    "pred_dict = {\n",
    "    'boxes': boxes[select_mask],\n",
    "    'size': torch.Tensor([image.shape[1], image.shape[2]]),\n",
    "    'box_label': box_label\n",
    "}\n",
    "vslzr.visualize(image, pred_dict, savedir=None, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ad18b9cce5171a92b1ace78d675cb7cfe7b38ef1dfda11fe1bc29cba1874dd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
